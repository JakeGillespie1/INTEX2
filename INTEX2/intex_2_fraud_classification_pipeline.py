# -*- coding: utf-8 -*-
"""INTEX 2-- Fraud Classification Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r56T2F0J6WSqRh43W5Tn85Fl4XOSOITJ

### **FRAUD CLASSIFICATION:**
Fraud Classification Pipeline: Build a classification model to predict whether each order is fraudulent.
Customer view: The customer should never see this prediction. However, you will need to make a fraud prediction when the customer places an order. If the prediction is “not fraud”, then show whatever order confirmation page you would normally intend to show. If the prediction is “fraud”, then inform them that their order needs to be reviewed (in the kindest way possible without arousing suspicion) before it can be fulfilled. In your video walkthrough of the website, be sure to point out how this prediction is made and the different view options based on the predicted outcome.


*   I will be using chapter 16.4 as a guide for this
*   Link to ch. 16.4 = https://app.myeducator.com/reader/web/1702au/jw0v9
*   I am thinking that the orders table will be good for this, what do you guys think?
*   Fraud is our label
*   2 class classification
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
#Import the data and test a model on a sample size of 1000
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/resources/FraudData.csv')
print(df.shape)
df = df.sample(n=1000, random_state=1)
df["fraud"] = df["fraud"].astype("object")
df.drop(columns=['date','OrderID','CustomerID'], inplace=True)
print(df.shape)
display(df)

#Import the functions from my file path...run some bivariate stats to get a better understanding of the data
import sys
sys.path.append('/content/drive/MyDrive/Colab Notebooks/functionLibrary')
import functions as mk

mk.bivariate(df, 'fraud')

#Drop any missing values from the sample (there are none in this sample)
df = mk.missing_drop(df, label='fraud')

#Get the X and y ready for training a classification model based on this small subset of data
from sklearn.tree import DecisionTreeClassifier

y = df.fraud
X = df.drop(columns=['fraud'])
X = pd.get_dummies(X, drop_first=True)
X.head()

#Run the model
model = DecisionTreeClassifier(max_depth=10)
y = y.astype('int')
model.fit(X, y)

#run some predictions based off of the model that we have trained - it looks like it is too overfit based off the accuracy score - we need to do better
df_results = pd.DataFrame({'Actual fraud':y, 'Predicted fraud':model.predict(X)})
print(f'Accuracy: {model.score(X, y)}')
df_results.head(10)

#Generate a new confusion matrix for the above model (looks overfit)
from sklearn import metrics
import matplotlib.pyplot as plt

cm = metrics.confusion_matrix(y, df_results['Predicted fraud'])
cm_display = metrics.ConfusionMatrixDisplay(cm, display_labels=['not fraud', 'fraud'])
cm_display.plot()
plt.show()

#Once again...too overfit based off of the output
# Several of these metrics have to work off of dummy codes rather than categorical values. Therefore:
y_test_dummies = pd.get_dummies(y, drop_first=True)
y_pred_dummies = pd.get_dummies(df_results['Predicted fraud'], drop_first=True)

# Accuracy  = (true positives + true negatives) / (total cases); ranges from 0 (worst) to 1 (best)
print(f"Accuracy:\t{metrics.accuracy_score(y, df_results['Predicted fraud'])}")

# Precision = (true positives / (true positives + false positives))
print(f"Precision:\t{metrics.precision_score(y_test_dummies, y_pred_dummies, labels=['no', 'yes'])}")

# Recall    = (true positives / (true positives + false negatives))
print(f"Recall:\t\t{metrics.recall_score(y_test_dummies, y_pred_dummies, labels=['no', 'yes'])}")

# F1        = (2 * (precision * recall) / (precision + recall))
print(f"F1:\t\t{metrics.f1_score(y_test_dummies, y_pred_dummies, labels=['no', 'yes'])}")

#generate a graphic for a decision tree model
from sklearn.tree import export_graphviz
from six import StringIO
from IPython.display import Image
import pydotplus

dot_data = StringIO()
export_graphviz(model, # This is the model we trained previously
                out_file=dot_data,
                filled=True,
                rounded=True,
                feature_names = X.columns,
                class_names=['not fraud','fraud'])

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('fraud_tree.png') # Save the image file
Image(graph.create_png())     # This is like plt.show()

#We are going to want to train a less over-fit classification model...these results look a bit better. Let's run a confusion matrix in the next cell
#to see how we are doing
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/resources/FraudData.csv')
df = df.sample(n=10000, random_state=1)

#Drop Null Values
df.dropna(inplace=True)
df.isna().sum() / df.shape[0]
df["fraud"] = df["fraud"].astype("str")

y = df.fraud
X = df.drop(columns=['fraud'])
X = pd.get_dummies(X, drop_first=True)
X = pd.DataFrame(MinMaxScaler().fit_transform(X), columns=X.columns)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)
clf = DecisionTreeClassifier(random_state=1).fit(X_train, y_train)
clf.score(X_test, y_test)

#Run the confusion matrix to visualize the model results a bit
from sklearn import metrics
import matplotlib.pyplot as plt

y_pred = clf.predict(X)
labels = y.sort_values().unique()

cm = metrics.confusion_matrix(y, y_pred)
cm_display = metrics.ConfusionMatrixDisplay(cm, display_labels=labels)
cm_display.plot()
plt.show()

#Generate another visualization to see the less over-fit model
from sklearn.tree import export_graphviz
from six import StringIO
from IPython.display import Image
import pydotplus

dot_data = StringIO()
export_graphviz(clf, # This is the model we trained previously
                out_file=dot_data,
                filled=True,
                rounded=True,
                feature_names = X.columns,
                class_names=labels)

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('fraud_tree.png') # Save the image file
Image(graph.create_png())     # This is like plt.show()

import sklearn.linear_model as lm
import sklearn.ensemble as se
import sklearn.tree as tree
from xgboost import XGBClassifier
from sklearn import svm
from sklearn import gaussian_process
from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn import svm
from sklearn.naive_bayes import CategoricalNB
from xgboost import XGBClassifier
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
import pandas as pd

#Let's use a better algorithm than decision tree model...here we run some tests to see which one is going to be most accurate
#It looks like XGBoost is the most accurate, but lets do a little digging with a larger dataset...
# Create a DataFrame to store and output the rsults
df_clf = pd.DataFrame(columns=['Family', 'Accuracy'])

# Insert a row into the DataFrame with the Accuracy score of the trained model from each algorithm to sort and compare
df_clf.loc['Logistic'] = ['Linear', lm.LogisticRegression(max_iter=1000).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Ridge'] = ['Linear', lm.RidgeClassifier().fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Stochastic Gradient Descent'] = ['Linear', lm.SGDClassifier(max_iter=1000, tol=1e-3).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Passive Agressive'] = ['Linear', lm.PassiveAggressiveClassifier(max_iter=1000, random_state=1, tol=1e-3).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Perceptron'] = ['Linear', lm.Perceptron(fit_intercept=False, max_iter=10, tol=None, shuffle=False).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Decision Tree'] = ['Decision Tree', tree.DecisionTreeClassifier().fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Extra Trees'] = ['Decision Tree', tree.ExtraTreeClassifier().fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['KNN'] = ['KNN', KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Support Vector Machine'] = ['SVM', svm.SVC(decision_function_shape='ovo').fit(X_train, y_train).score(X_test, y_test)] # Remove the parameter for two-class model
df_clf.loc['Bagging'] = ['Ensemble', se.BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['AdaBoost'] = ['Ensemble', se.AdaBoostClassifier(n_estimators=100, random_state=1).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Extra Trees ensemble'] = ['Ensemble', se.ExtraTreesClassifier(n_estimators=100, random_state=1).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Random Forest'] = ['Ensemble', se.RandomForestClassifier(n_estimators=10).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Histogram Gradient Boosting'] = ['Ensemble', se.HistGradientBoostingClassifier(max_iter=100).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Gradient Boosting'] = ['Ensemble', se.GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Neural Network'] = ['Neural Network', MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1).fit(X_train, y_train).score(X_test, y_test)]

# XGBoost needs the label in the format of [0, 1, 2, 3, ..., n - 1]. It can't handle categorical values
from sklearn.preprocessing import LabelEncoder
y_encoded = LabelEncoder().fit(y).transform(y) # This line converts the y from ['yes', 'no', 'no'] to [1, 0, 0], much like dummy coding
# Now we have to resplit the data with these encoded y values:
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=1)
df_clf.loc['XGBoost'] = ['Ensemble', XGBClassifier().fit(X_train, y_train).score(X_test, y_test)]

# Now print out the DataFrame sorted by best to worst
df_clf.sort_values(by=['Accuracy'], ascending=False)

#Import the data again and run through the modeling process with the entire dataset
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/resources/FraudData.csv')
df.drop(columns=['date','OrderID','CustomerID'], inplace=True)
print(f"Number of transactions in the sample: {df.shape[0]}")
display(df.head())

#Get Missing Values
df.isna().sum()

#Bin categories
def bin_categories(df, features=[], cutoff=0.05, replace_with='Other', messages=True):
  import pandas as pd

  if len(features) == 0: features = df.columns #If no features are specified, bin all features

  for feat in features:
    if feat in df.columns: #make sure that they do not accidentally enter a feature name that does not exist
      if not pd.api.types.is_numeric_dtype(df[feat]):
        other_list = df[feat].value_counts()[df[feat].value_counts() / df.shape[0] < cutoff].index
        df.loc[df[feat].isin(other_list), feat] = replace_with
        if messages and len(other_list) > 0: print(f'{feat} has been binned by setting {other_list} to {replace_with}')
    else:
      if messages: print(f'{feat} not found in the DataFrame provided. No binning performed')

  return df

def impute_KNN(df, nn=5):
  from sklearn.experimental import enable_iterative_imputer
  from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer
  import numpy as np, pandas as pd

  # Convert to dummy codes first
  for col in df:
    if not pd.api.types.is_numeric_dtype(df[col]):
      df = pd.get_dummies(df, columns=[col], drop_first=True)

  imp = KNNImputer(n_neighbors=nn, weights="uniform")
  df = pd.DataFrame(imp.fit_transform(df), columns=df.columns)

  return df

#Data cleaning (bin small categories and replace any missing values with estimates derived from their k nearest neighbors in the feature space)
df = bin_categories(df)
df = impute_KNN(df)
display(df.head())

#Get features all set up properly with dummies
y = df.fraud
X = df.drop(columns=['fraud'])
X = pd.get_dummies(X, drop_first=True)
X.head()

#Create the training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=1)
X_test.head()

#Train the classification model again with the whole dataset to view its accuracy just for fun :)
clf = DecisionTreeClassifier(random_state=1).fit(X_train, y_train)

#Run the prediction with the trained model to test it out.
y_pred = clf.predict(X_test)
df_pred_actual = pd.DataFrame({'PREDICTED_VALUES':y_pred, 'ACTUAL_VALUES':y_test})
df_pred_actual.head(10)

#Display the confusion matrix - There is still work to do!
labels = y.sort_values().unique()

conf_matrix = metrics.confusion_matrix(y_test, y_pred)
conf_matrix_display = metrics.ConfusionMatrixDisplay(conf_matrix, display_labels=labels)
conf_matrix_display.plot()
plt.show()

#Print out accuracy metrics for the model that we are working with
y_test_dummies = pd.get_dummies(y_test, drop_first=True)
y_pred_dummies = pd.get_dummies(y_pred, drop_first=True)


print(f'Accuracy:\t{metrics.accuracy_score(y_test, y_pred)}')
print(f'Precision:\t{metrics.precision_score(y_test_dummies, y_pred_dummies, labels=[0.0,1.0])}')
print(f'Recall:\t\t{metrics.recall_score(y_test_dummies, y_pred_dummies, labels=[0.0,1.0])}')
print(f'F1:\t\t{metrics.f1_score(y_test_dummies, y_pred_dummies, labels=[0.0,1.0])}')

from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt

# We must standardize the data first to make the coefficients comparable
X_minmax = pd.DataFrame(MinMaxScaler().fit_transform(X), columns=X.columns)

# Use the scaled X, but the same y
clf = LogisticRegression(max_iter=10000).fit(X_minmax, y)

# Store the coefficients in a dataframe
df_coef = pd.DataFrame({'Coefficients':clf.coef_[0]}, index=clf.feature_names_in_)
df_coef.sort_values(by=['Coefficients'], ascending=False, inplace=True)

# Visualize the coefficients to make then easier to interpret
plt.bar(list(df_coef.index), list(df_coef.Coefficients))
plt.xticks(rotation=90)
plt.show()

# Store the coefficients in a dataframe
df_coef = pd.DataFrame({'Coefficients':clf.coef_[0]}, index=clf.feature_names_in_)
df_coef['sign'] = 'positive'
for coef in df_coef.itertuples():
  if coef[1] < 0:
    df_coef.at[coef[0], 'sign'] = 'negative'
    df_coef.at[coef[0], 'Coefficients'] = coef[1] * -1
df_coef.sort_values(by=['Coefficients'], inplace=True)

colors = {'positive': 'mediumseagreen', 'negative': 'lightcoral'}
df_coef['Coefficients'].plot(kind='barh', color=[colors[i] for i in df_coef['sign']])

labels = df_coef['sign'].unique()
handles = [plt.Rectangle((0,0),1,1, color=colors[l]) for l in labels]
plt.legend(handles, labels, title="Relationship")
plt.show()

def fit_cv_classification_expanded(df, label, k=10, r=5, repeat=True, random_state=1):
  import sklearn.linear_model as lm, pandas as pd, sklearn.ensemble as se, numpy as np
  from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score
  from numpy import mean, std
  from sklearn import svm
  from sklearn import gaussian_process
  from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel
  from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
  from sklearn import svm
  from sklearn.naive_bayes import CategoricalNB
  from xgboost import XGBClassifier
  from sklearn import preprocessing
  from sklearn.neural_network import MLPClassifier

  X = df.drop(columns=[label])
  y = df[label]

  if repeat:
    cv = RepeatedKFold(n_splits=k, n_repeats=r, random_state=random_state)
  else:
    cv = KFold(n_splits=k, random_state=random_state, shuffle=True)

  fit = {}    # Use this to store each of the fit metrics
  models = {} # Use this to store each of the models

  # Create the model objects
  model_log = lm.LogisticRegression(max_iter=100)
  model_logcv = lm.RidgeClassifier()
  model_sgd = lm.SGDClassifier(max_iter=1000, tol=1e-3)
  model_pa = lm.PassiveAggressiveClassifier(max_iter=1000, random_state=random_state, tol=1e-3)
  model_per = lm.Perceptron(fit_intercept=False, max_iter=10, tol=None, shuffle=False)
  model_knn = KNeighborsClassifier(n_neighbors=3)
  model_svm = svm.SVC(decision_function_shape='ovo') # Remove the parameter for two-class model
  model_nb = CategoricalNB()
  model_bag = se.BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)
  model_ada = se.AdaBoostClassifier(n_estimators=100, random_state=random_state)
  model_ext = se.ExtraTreesClassifier(n_estimators=100, random_state=random_state)
  model_rf = se.RandomForestClassifier(n_estimators=10)
  model_hgb = se.HistGradientBoostingClassifier(max_iter=100)
  model_vot = se.VotingClassifier(estimators=[('lr', model_log), ('rf', model_ext), ('gnb', model_hgb)], voting='hard')
  model_gb = se.GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)
  estimators = [('ridge', lm.RidgeCV()), ('lasso', lm.LassoCV(random_state=random_state)), ('knr', KNeighborsRegressor(n_neighbors=20, metric='euclidean'))]
  final_estimator = se.GradientBoostingRegressor(n_estimators=25, subsample=0.5, min_samples_leaf=25, max_features=1, random_state=random_state)
  model_st = se.StackingRegressor(estimators=estimators, final_estimator=final_estimator)
  model_xgb = XGBClassifier()
  model_nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=random_state)

  # Fit a cross-validated R squared score and add it to the dict
  fit['Logistic'] = mean(cross_val_score(model_log, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['Ridge'] = mean(cross_val_score(model_logcv, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['SGD'] = mean(cross_val_score(model_sgd, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['PassiveAggressive'] = mean(cross_val_score(model_pa, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['Perceptron'] = mean(cross_val_score(model_per, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['KNN'] = mean(cross_val_score(model_knn, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['SVM'] = mean(cross_val_score(model_svm, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['NaiveBayes'] = mean(cross_val_score(model_nb, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['Bagging'] = mean(cross_val_score(model_bag, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['AdaBoost'] = mean(cross_val_score(model_ada, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['ExtraTrees'] = mean(cross_val_score(model_ext, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['RandomForest'] = mean(cross_val_score(model_rf, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['HistGradient'] = mean(cross_val_score(model_hgb, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['Voting'] = mean(cross_val_score(model_vot, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['GradBoost'] = mean(cross_val_score(model_gb, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['XGBoost'] = mean(cross_val_score(model_xgb, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  fit['NeuralN'] = mean(cross_val_score(model_nn, X, y, scoring='accuracy', cv=cv, n_jobs=-1))

  # XGBoost needs to LabelEncode the y before fitting the model
  from sklearn.preprocessing import LabelEncoder
  le = LabelEncoder().fit(y)
  y_encoded = le.transform(y.copy())
  fit['XGBoost'] = mean(cross_val_score(model_xgb, X, y_encoded, scoring='accuracy', cv=cv, n_jobs=-1))

  # Add the model to another dictionary; make sure the keys have the same names as the list above
  models['Logistic'] = model_log
  models['Ridge'] = model_logcv
  models['SGD'] = model_sgd
  models['PassiveAggressive'] = model_pa
  models['Perceptron'] = model_per
  models['KNN'] = model_knn
  models['SVM'] = model_svm
  models['NaiveBayes'] = model_nb
  models['Bagging'] = model_bag
  models['AdaBoost'] = model_ada
  models['ExtraTrees'] = model_ext
  models['RandomForest'] = model_rf
  models['HistGradient'] = model_hgb
  models['Voting'] = model_vot
  models['GradBoost'] = model_gb
  models['XGBoost'] = model_xgb
  models['NeuralN'] = model_nn

  # Add the fit dictionary to a new DataFrame, sort, extract the top row, use it to retrieve the model object from the models dictionary
  df_fit = pd.DataFrame({'Accuracy':fit})
  df_fit.sort_values(by=['Accuracy'], ascending=False, inplace=True)
  best_model = df_fit.index[0]
  print(df_fit)

  return models[best_model].fit(X, y)

def Xandy(df, label):
  import pandas as pd
  y = df[label]
  X = df.drop(columns=[label])
  return X, y

def dummy_code(X):
  import pandas as pd
  X = pd.get_dummies(X, drop_first=True)
  return X

def fit_cv_classification(df, k, label, repeat=True, algorithm='ensemble', random_state=1, messages=True):
  from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score
  import pandas as pd
  from numpy import mean
  X, y = Xandy(df, label)
  X = dummy_code(X)
  if repeat:  cv = RepeatedKFold(n_splits=k, n_repeats=5, random_state=1)
  else:       cv = KFold(n_splits=k, random_state=1, shuffle=True)
  if algorithm == 'linear':
    from sklearn.linear_model import RidgeClassifier, SGDClassifier
    model1 = RidgeClassifier(random_state=random_state)
    model2 = SGDClassifier(random_state=random_state)
    score1 = mean(cross_val_score(model1, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
    score2 = mean(cross_val_score(model2, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  elif algorithm == 'ensemble':
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    model1 = RandomForestClassifier(random_state=random_state)
    model2 = GradientBoostingClassifier(random_state=random_state)
    score1 = mean(cross_val_score(model1, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
    score2 = mean(cross_val_score(model2, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  else:
    from sklearn.neural_network import MLPClassifier
    from sklearn.neighbors import KNeighborsClassifier
    model1 = MLPClassifier(random_state=random_state, max_iter=10000)
    model2 = KNeighborsClassifier()
    score1 = mean(cross_val_score(model1, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
    score2 = mean(cross_val_score(model2, X, y, scoring='accuracy', cv=cv, n_jobs=-1))
  if messages:
    print('Accuracy', '{: <25}'.format(type(model1).__name__), round(score1, 4))
    print('Accuracy', '{: <25}'.format(type(model2).__name__), round(score2, 4))
  if score1 > score2: return model1.fit(X, y)
  else:               return model2.fit(X, y)

def import_data(path, messages=True):
  import pandas as pd

  #Note: this pulls from a static csv...In the real world, we would pull from a live data
  #source or data warehouse.
  df = pd.read_csv(path)

  # Messages like these are useful when building out the pipeline initially
  # But they can be turned off once the pipeline is ready
  if messages: print(df.shape)

  return df

def select_features(df, label, model, max='auto'):
  from sklearn.feature_selection import SelectFromModel
  import pandas as pd

  X, y = Xandy(df, label)

  if max != 'auto': # Either leave the default or specify a percent of the features to keep
    sel = SelectFromModel(model, prefit=True, max_features=round(max*df.drop(columns=[label]).shape[1]))
  else:
    sel = SelectFromModel(model, prefit=True)
  sel.transform(X)

  columns = list(X.columns[sel.get_support()])
  columns.append(label) # Add the label back into the list of features to keep
  return df[columns]    # Return the dataset minus the bad features

def dump_joblib(model, file_name):
  import joblib
  joblib.dump(model, file_name)

def load_joblib(file_name):
  import joblib
  return joblib.load(file_name)

import pandas as pd
#Now that we have run through that process, lets make sure we fully understand the data and choose the BEST model to run predictions
#Import ENTIRE DATASET
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/resources/FraudData.csv')
print(df.shape)
df.head()

import seaborn as sns
import matplotlib.pyplot as plt

# We will use this DataFrame to store the results of the univariate analysis
df_results = pd.DataFrame(columns=['flag', 'type', 'missing', 'unique', 'min', 'q1', 'median',
                                    'q3', 'max', 'mode', 'mean', 'std', 'skew', 'kurt'])

for col in df:  # Iterate through each column in the DataFrame
  # Calculate features that apply to all data types
  dtype = df[col].dtype
  missing = df[col].isna().sum()
  unique = df[col].nunique()
  mode = df[col].mode()[0]

  if pd.api.types.is_numeric_dtype(df[col]): # Depending on whether each column is numeric or not, we will calculate different features
    # Features for numeric dtypes only
    min = df[col].min()
    q1 = df[col].quantile(0.25)
    median = df[col].median()
    q3 = df[col].quantile(0.75)
    max = df[col].max()
    mean = df[col].mean()
    std = df[col].std()
    skew = df[col].skew()
    kurt = df[col].kurt()

    # Insert a record into df_results to display the univariate properties relevant to numeric features
    df_results.loc[col] = ['-', dtype, missing, unique, min, q1, median, q3, max, mode,
                          round(mean, 2), round(std, 2), round(skew, 2), round(kurt, 2)]
  else:
    # This line will count the number of group values that represent less than 5% of the data
    flag = df[col].value_counts()[(df[col].value_counts() / df.shape[0]) < 0.05].shape[0]
    # Insert a record into df_results to display the univariate properties relevant to categorical features
    df_results.loc[col] = [flag, dtype, missing, unique, '-', '-', '-', '-', '-',
                          mode, '-', '-', '-', '-']

# Next, let's create a set of countplots for the categorical features and histograms for the numeric features
# First, filter df_results into two sets of features: one for countplots and one for histograms
countplots = df_results[df_results['type'] == 'object']  # count the number of features that are objects
histograms = df_results[(df_results['type'] == 'float64') | (df_results['unique'] > 10)] # need histograms

# Second, create a loop that dynamically plots the countplots and adjust the figure size based on the number of features
f, ax = plt.subplots(1, countplots.shape[0], figsize=[countplots.shape[0] * 2, 2])
for i, col in enumerate(countplots.index):
  g = sns.countplot(data=df, x=col, color='g', ax=ax[i]);
  g.set_yticklabels('')
  g.set_ylabel('')
  ax[i].tick_params(labelrotation=90, left=False)
  ax[i].xaxis.set_label_position('top')
  sns.despine(left=True, top=True, right=True)

# Third, create a loop that dynamically plots the histograms and adjust the figure size based on the number of features
f, ax = plt.subplots(1, histograms.shape[0], figsize=[histograms.shape[0] * 2, 2])
for i, col in enumerate(histograms.index):
  g = sns.histplot(data=df, x=col, color='b', ax=ax[i], kde=True);
  g.set_yticklabels(labels=[])
  g.set_ylabel('')
  ax[i].tick_params(left=False)
  sns.despine(left=True, top=True, right=True)
plt.show()

# Finally, display the univariate properties in a DataFrame
df_results

# Drop rows with missing data and view the record count before and after to ensure it worked as expected
print(df.shape)
df.dropna(inplace=True)
df.shape

#Drop unneded columns (uniqueness was a large thing we noted)
df.drop(columns=['date', 'OrderID', 'CustomerID'], inplace=True)

# Divide the dataset into features and label
y = df.fraud
X = df.drop(columns=['fraud'])

# Dummy-code the features only
X = pd.get_dummies(X, drop_first=True)

# Split the dataset into training set and test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

import sklearn.linear_model as lm
import sklearn.ensemble as se
import sklearn.tree as tree
from xgboost import XGBClassifier
from sklearn import svm
from sklearn import gaussian_process
from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn import svm
from sklearn.naive_bayes import CategoricalNB
from xgboost import XGBClassifier
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier

# Create a DataFrame to store and output the rsults
df_clf = pd.DataFrame(columns=['Family', 'Accuracy'])

# Insert a row into the DataFrame with the Accuracy score of the trained model from each algorithm to sort and compare
df_clf.loc['Logistic'] = ['Linear', lm.LogisticRegression(max_iter=10000).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Ridge'] = ['Linear', lm.RidgeClassifier().fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Stochastic Gradient Descent'] = ['Linear', lm.SGDClassifier(max_iter=1000, tol=1e-3).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Passive Agressive'] = ['Linear', lm.PassiveAggressiveClassifier(max_iter=1000, random_state=1, tol=1e-3).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Perceptron'] = ['Linear', lm.Perceptron(fit_intercept=False, max_iter=10, tol=None, shuffle=False).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Decision Tree'] = ['Decision Tree', tree.DecisionTreeClassifier(random_state=1).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Extra Trees'] = ['Decision Tree', tree.ExtraTreeClassifier(random_state=1).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['KNN'] = ['KNN', KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Support Vector Machine'] = ['SVM', svm.SVC(decision_function_shape='ovo').fit(X_train, y_train).score(X_test, y_test)] # Remove the parameter for two-class model
df_clf.loc['Bagging'] = ['Ensemble', se.BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['AdaBoost'] = ['Ensemble', se.AdaBoostClassifier(n_estimators=100, random_state=1).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Extra Trees ensemble'] = ['Ensemble', se.ExtraTreesClassifier(n_estimators=100, random_state=1).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Random Forest'] = ['Ensemble', se.RandomForestClassifier(n_estimators=10, random_state=1).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Histogram Gradient Boosting'] = ['Ensemble', se.HistGradientBoostingClassifier(max_iter=100, random_state=1).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Gradient Boosting'] = ['Ensemble', se.GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=1).fit(X_train, y_train).score(X_test, y_test)]
df_clf.loc['Neural Network'] = ['Neural Network', MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1).fit(X_train, y_train).score(X_test, y_test)]

# XGBoost needs the label in the format of [0, 1, 2, 3, ..., n - 1]. It can't handle categorical values
from sklearn.preprocessing import LabelEncoder
y_encoded = LabelEncoder().fit(y).transform(y) # This line converts the y from ['yes', 'no', 'no'] to [1, 0, 0], much like dummy coding
# Now we have to resplit the data with these encoded y values:
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=1)
df_clf.loc['XGBoost'] = ['Ensemble', XGBClassifier(random_state=1).fit(X_train, y_train).score(X_test, y_test)]

# Now print out the DataFrame sorted by best to worst
df_clf.sort_values(by=['Accuracy'], ascending=False)

#Based off of the df above, we should use GradientBoostingClassifier
clf = se.GradientBoostingClassifier(n_estimators=150, learning_rate=1.0, max_depth=1, random_state=1).fit(X_train, y_train)

#Display the columns of the features to help us make predictions (see below)
pd.set_option('display.max_columns', None)
X

#Run predictions to understand the model better
clf.predict([[7,20,0,0,0,0,0,1,0,1,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,1]])[0]

!pip install skl2onnx

#Import ONNX stuff
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType

#Convert the model to a proper ONNX format
initial_type = [('float_input',FloatTensorType([None, X_train.shape[1]]))]
onnx_model = convert_sklearn(model, initial_types=initial_type)

#save the ONNX model (wb means to write to binary)
with open("gradient_boost_model.onnx", "wb") as f:
  f.write(onnx_model.SerializeToString())